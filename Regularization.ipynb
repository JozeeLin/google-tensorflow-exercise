{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regularization.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/JozeeLin/google-tensorflow-exercise/blob/master/Regularization.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "f_kgMZxpZHaS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 简化正则化:L2正则化\n",
        "根据奥卡姆剃刀定律，我们可以通过降低复杂模型的复杂度来防止过拟合。这种原则成为正则化。\n",
        "\n",
        "也就是说，并非只是以最小化损失(经验风险最小化)为目标:\n",
        "\n",
        "$\\rm{minimize}(\\rm{Loss}(\\rm{Data}|Model))$\n",
        "\n",
        "而是以最小化损失和复杂度为目标，这称为结构风险最小化:\n",
        "\n",
        "$\\rm{minimize}(\\rm{Loss}(\\rm{Data|Model})+\\rm{complexity}(Model))$\n",
        "\n",
        "现在，我们的训练优化算法是一个由两项内容组成的函数:一个是损失项，用于衡量模型与数据的拟合度，另一个是正则化项，用于衡量模型复杂度。\n",
        "\n",
        "机器学习速成课程重点介绍了两种衡量模型复杂度的常见方式(这两种方式有些相关):\n",
        "- 将模型复杂度作为模型中所有特征的权重的函数(L2)\n",
        "- 将模型复杂度作为具有非零权重的特征总数的函数(L1)\n",
        "如果模型复杂度是权重的函数，则特征权重的绝对值越高，对模型复杂度的贡献就越大。\n",
        "\n",
        "使用L2正则化公式来量化复杂度，该公式将正则化项定义为所有特征权重的平方和:\n",
        "\n",
        "$\\rm{L2 regularization term = \\|w\\|_2^2 = w_1^2+w_2^2+\\dots+w_n^2}$\n",
        "\n",
        "在这个公式中，接近于0的权重对模型复杂度几乎没有影响，而离群值权重则可能会产生巨大的影响。\n",
        "\n",
        "例如，某个线性模型具有如下权重:\n",
        "\n",
        "${w_1=0.2,w_2=0.5,w_3=5,w_4=1,w_5=0.25,w_6=0.75}$\n",
        "\n",
        "L2正则化项为:\n",
        "\n",
        "$w_1^2+w_2^2+w_3^2+w_4^2+w_5^2+w_6^2=26.915$\n",
        "\n",
        "模型开发者通过以下方式来调整正则化项的整体影响:用正则化项的值乘以名为**lambda**(又称为**正则化率**)的标量。也就是说，模型开发者会执行以下运算:\n",
        "\n",
        "$\\rm{minimize(Loss(Data|Model)+\\lambda complexity(Model))}$\n",
        "\n",
        "执行L2正则化对模型具有如下影响:\n",
        "- 使权重值接近于0(但并非正好为0)\n",
        "- 使权重的平均值接近于0，且呈正态(钟形曲线或高斯曲线)分布\n",
        "\n",
        "增加lambda值将增加正则化效果。\n",
        "\n",
        "在选择lambda值时，目标是在简单化和训练数据拟合之间达到适当的平衡:\n",
        "- 如果您的lambda值过高，则模型会非常简单，但是您将面临数据欠拟合的风险。模型无法从训练数据中获得足够的信息来做出有用的预测\n",
        "- 如果lambda值过低，则模型会比较复杂，并且会面临数据过拟合的风险。模型将因获得过的训练数据特点方面的信息而无法泛化到新数据\n",
        "\n",
        "# 稀疏性正则化:L1正则化\n",
        "稀疏矢量通常包含许多维度。创建特征组合会导致包含更多维度。由于使用此类高维度特征矢量，因此模型可能会非常庞大，并且需要大量的内存。\n",
        "\n",
        "在高维度稀疏矢量中，最好尽可能使权重正好降至0.正好为0的权重基本上会使相应特征从模型中移除。将特征设为0可节省内存空间，且可以减少模型中的噪点。\n",
        "\n",
        "### L1和L2的区别\n",
        "你可以将L2导数的作用理解为每次移除权重的x%。对于任意数字，即使按每次减去x%的幅度执行数十亿次减法，最后得出的值也绝不会正好为0.总而言之，L2通常不会是权重变为0。\n",
        "\n",
        "你可以将L1导数的作用理解为每次从权重中减去一个常数。不过，由于减去的是绝对值，L1在0处具有不连续性，这会导致与0相交的减法结果变为0.例如，如果减法使权重从+0.1变成-0.2，L1便会将权重设为0.就这样，L1使权重变为0了。\n",
        "\n",
        "L1正则化-减少所有权重的绝对值-证明对宽度模型非常有效。"
      ]
    },
    {
      "metadata": {
        "id": "Nyhb4VGCY-VQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}