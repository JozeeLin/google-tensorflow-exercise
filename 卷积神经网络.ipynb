{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "卷积神经网络.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/JozeeLin/google-tensorflow-exercise/blob/master/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "PXeprKLxYe0u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 卷积神经网络简介\n",
        "卷积神经网络最初是为解决图像识别等问题设计的，当然其现在的应用不仅限于图像和视频，也可用于时间序列信号，比如音频信号、文本数据等。\n",
        " \n",
        "在早期的图像识别研究中，最大的挑战是如何组织特征，因为图像数据不像其他类型的数据那样可以通过人工理解来提取特征。\n",
        " \n",
        "在股票预测等模型中，我们可以从原始数据中提取过往的交易价格波动、市盈率、市净率、盈利增长等金融因子，这既是特征工程。\n",
        " \n",
        "但是在图像中，我们很难根据人为理解提取出有效而丰富的特征。\n",
        " \n",
        "在深度学习出现之前，我们必须辅助SIFT、HoG等算法提取具有良好区分性的特征，再集合SVM等机器学习算法进行图像识别。\n",
        " \n",
        "SIFT对一定程度内的缩放、平移、旋转、视角改变、亮度调整等畸变，都具有不变性，是当时最重要的图像特征提取方法之一。\n",
        " \n",
        "在之前只能依靠SIFT等特征提取算法才能勉强进行可靠的图像识别。\n",
        " \n",
        "CNN可以直接使用图像的原始像素作为输入，而不必先使用SIFT等算法提取特征，减轻了使用传统算法如SVM时必需要做得大量重复、繁琐的数据预处理工作。\n",
        " \n",
        "CNN的最大特点在于卷积的权值共享结构，可以大幅减少神经网络的参数量，防止过拟合的同时又降低了神经网络的复杂度。\n",
        " \n",
        "一般的卷积神经网络由多个卷积层构成，每个卷积层中通常会进行如下几个操作:\n",
        " 1. 图像通过多个不同的卷积核的滤波，并加偏置(bias),提取出局部特征，每一个卷积核会映射出一个新的2D图像\n",
        " 2. 将前面卷积核的滤波输出结果，进行非线性的激活函数处理。目前最常见的是使用ReLU函数，而以前sigmoid函数用得比较多\n",
        " 3. 对激活函数的结果再进行池化操作(即降采样，比如将2x2的图片降为1x1的图片)，目前一般是使用最大池化，保留最显著的特征，并提升模型的畸变容忍能力\n",
        " <br>\n",
        " \n",
        "这几个步骤就构成了最常见的卷积层，当然也可以再加上一个LRN（局部响应归一化层）层，目前非常流行的Trick还有Batch Normalization等。\n",
        " \n",
        "一个卷积层中可以有多个不同的卷积核，而每一个卷积核都对应一个滤波后映射出的新图像，同一个新图像中每一个图像都来自完全相同的卷积核，这就是卷积核的全职共享。\n",
        " \n",
        "这一小块区域内的像素是相互关联的，每一个神经元不需要接收全部像素点的信息，只需要接收局部的像素点作为输入，而后将所有这些神经元收到的局部信息综合起来就可以得到全局的信息。\n",
        "这样就可以将之前的全连接的模式修改为局部连接，之前隐含层的每一个隐含节点都和全部像素相连，现在我们只需要将每一个隐含节点连接到局部的像素节点。\n",
        " \n",
        "通过局部连接的方法，将连接数从1万亿降低到1亿，但仍然偏多，需要继续降低参数量。现在隐含层每一个节点都与10x10的像素相连，也就是每一个隐含节点都拥有100个参数。假设我们的局部连接方式是卷积操作，即默认每一个**隐藏节点的参数都完全一样**，那我们的参数不再是1亿，而是100。**参数量只跟卷积核的大小有关，这也就是所谓的权值共享**。\n",
        " \n",
        "卷积神经网络的要点就是局部连接、权值共享和池化层中的降采样。其中，局部连接和权值共享降低了参数数量，使训练复杂度降低，并减轻了过拟合。\n",
        " \n",
        "同时权值共享还赋予了卷积神经网络对平移的容忍性，而池化层降采样则进一步降低了输出餐数量，并赋予模型对轻度型变得容忍性，提高了模型的泛化能力。\n",
        " \n",
        "LeNet5当时的特性有如下几点：\n",
        "1. 每个卷积层包含三个部分：卷积、池化和非线性激活函数\n",
        "2. 使用卷积提取空间特征\n",
        "3. 降采样(Subsample)的平均池化层(Average Pooling)\n",
        "4. 双曲正切(Tanh)或S型(Sigmoid)的激活函数\n",
        "5. MLP作为最后的分类器\n",
        "6. 层与层之间的稀疏连接减少计算复杂度\n",
        "  "
      ]
    },
    {
      "metadata": {
        "id": "Htf-YtoEYSiB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "53ad13fa-e3ca-4aa1-94b2-e66e828f42dc"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import tensorflow as tf\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
        "sess = tf.InteractiveSession()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ndLPAYgxAqO5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def weight_variable(shape):\n",
        "  #用于重复初始化权重和偏置\n",
        "  \n",
        "  #使用截断的正态分布噪声来打破完全对称，标准差设为0.1\n",
        "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
        "  return tf.Variable(initial)\n",
        "\n",
        "def bias_variable(shape):\n",
        "  #使用ReLU，也需要给偏置增加一些小的正值0.1来避免死亡节点\n",
        "  initial = tf.constant(0.1, shape=shape)\n",
        "  return tf.Variable(initial)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MSfjNLU2B03M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "卷积层、池化层也是接下来要重复使用的，因此也为他们分别定义创建函数。"
      ]
    },
    {
      "metadata": {
        "id": "vAZt8RH9BGIg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv2d(x,W):\n",
        "  '''\n",
        "  tf.nn.conv2d是tf中的2维卷积函数，参数中x是输入，W是卷积的参数，如[5,5,1,32],前两个表示卷积核的尺寸，\n",
        "  第三个表示有多少个channel，因为是灰度，所以为1，如果是RGB的为3，最后一个表示卷积核的数量\n",
        "  '''\n",
        "  return tf.nn.conv2d(x,W,strides=[1,1,1,1], padding='SAME')\n",
        "\n",
        "def max_pool_2x2(x):\n",
        "  '''\n",
        "  strides代表卷积模块移动的步长，都是1代表会不遗漏的划过的图片的每一个点\n",
        "  padding代表卷积模板移动的步长，这里的SAME代表给边界加上padding让卷积的输出和输入保持同样的尺寸\n",
        "  tf.nn.max_pool是tf中的最大池化函数，这里使用2x2的最大池化，即将一个2x2的像素降为1x1的像素。最大池化会保留原始像素块中灰度值最高的那一个像素，即保留最显著的特征。\n",
        "  '''\n",
        "  return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1],padding='SAME')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "finXQKkYEAYg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = tf.placeholder(tf.float32, [None, 784])\n",
        "y_ = tf.placeholder(tf.float32, [None, 10])\n",
        "#因为卷积神经网络会利用空间结构信息，因此需要将1D的输入向量转为2D的图片结构，即从1x784的形式转为原始的28x28的结构。[-1,28,28,1]，-1表示样本数量不固定，1代表颜色通道数量\n",
        "x_image = tf.reshape(x, [-1,28,28,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ou6QjaXJETmh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#定义第一个卷积层。使用前面写好的函数进行参数初始化，包括weights和bias\n",
        "W_conv1 = weight_variable([5,5,1,32])\n",
        "b_conv1 = bias_variable([32])\n",
        "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1)+b_conv1)\n",
        "h_pool1 = max_pool_2x2(h_conv1)#对卷积的输出结果进行池化操作"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8zLUNvXjFbAo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#定义第二个卷积层，唯一不同的是，这一层的卷积核数量为64\n",
        "W_conv2 = weight_variable([5,5,32,64])\n",
        "b_conv2 = bias_variable([64])\n",
        "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2)+b_conv2)\n",
        "h_pool2 = max_pool_2x2(h_conv2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gvYrl_szGE7r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "W_fc1 = weight_variable([7*7*64,1024])\n",
        "b_fc1 = bias_variable([1024])\n",
        "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
        "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1)+b_fc1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OXeanempHUoF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#为了减轻过拟合，使用一个dropout层。在训练时，我们通过随机丢弃一部分节点的数据来减轻过拟合，预测时则保留全部数据来追求最好的预测性能\n",
        "keep_prob = tf.placeholder(tf.float32)\n",
        "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "it8csMCTH3iE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "W_fc2 = weight_variable([1024,10])\n",
        "b_fc2 = bias_variable([10])\n",
        "#最后我们将dropout层的输出连接一个softmax层，得到最后的概率输出\n",
        "y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop,W_fc2)+b_fc2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c2rz9I_3IIZU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#定义损失函数为cross entropy和之前一样，但是优化器使用Adam，并使用一个比较小的学习速率\n",
        "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_*tf.log(y_conv),reduction_indices=[1]))\n",
        "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8B8tjKXAI_iM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#再继续定义评测准确率的操作\n",
        "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MM1rFQtwJR7C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#开始训练过程。首先初始化所有参数，设置训练时dropout的keep_prob为0.5\n",
        "tf.global_variables_initializer().run()\n",
        "for i in range(20000):\n",
        "  batch = mnist.train.next_batch(50)\n",
        "  if i%100 == 0:\n",
        "    train_accuracy = accuracy.eval(feed_dict={x:batch[0],y_:batch[1],keep_prob:1.0})\n",
        "    \n",
        "  train_step.run(feed_dict={x:batch[0], y_:batch[1], keep_prob:0.5})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bkb77IwpUbBh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "042c3ce0-cfda-4f85-98e5-08e8ab8efd58"
      },
      "cell_type": "code",
      "source": [
        "print('test accuracy %g' % accuracy.eval(feed_dict={\n",
        "    x:mnist.test.images,y_:mnist.test.labels,keep_prob:1.0\n",
        "}))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test accuracy 0.9911\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EZMytsNLK6xk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 实现进阶的卷积网络\n",
        "本节使用的数据集是CIFAR-10，包含60000张32x32的彩色图像，其中训练集为50000张，测试集为10000张。10种类别。每一类6000张，分别为airplane,automobile,bird,cat,deer,dog,frog,horse,ship,truck。\n",
        "\n",
        "在这个卷积神经网络中，我们使用一些新的技巧\n",
        "- 对weight进行L2的正则化\n",
        "- 对图片进行了翻转、随机剪切等数据增强，制造了更多样本\n",
        "- 在每个卷积-最大池化层后面使用了LRN层，增强了模型的泛化能力"
      ]
    },
    {
      "metadata": {
        "id": "Xq6gzisnUvq6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "b9bf0f66-aa16-4515-d823-bc43f1af6434"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tensorflow/models.git 'mymodels'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'mymodels'...\n",
            "remote: Counting objects: 16243, done.\u001b[K\n",
            "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
            "remote: Total 16243 (delta 13), reused 13 (delta 7), pack-reused 16214\u001b[K\n",
            "Receiving objects: 100% (16243/16243), 424.08 MiB | 39.85 MiB/s, done.\n",
            "Resolving deltas: 100% (9616/9616), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hIA85xJXW46w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "985b77b5-a295-4508-d8be-7b65d4dc2b35"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datalab  MNIST_data  models  mymodels\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VpZ3f1tYXf2_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1ec1ab0f-9b6a-4e91-b90b-3d74c0b46be2"
      },
      "cell_type": "code",
      "source": [
        "!ls mymodels/tutorials/image/"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "alexnet  cifar10  cifar10_estimator  imagenet  __init__.py  mnist  __pycache__\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AKbW-aAeKY7e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RlTRcMyrZndS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1ca911a8-d7bd-42d3-ccd4-55ecb54d5a1e"
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "F-fgohv2bztd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('mymodels/tutorials/image/cifar10')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "af7PMD0Cb678",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import cifar10,cifar10_input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OV6cK4VsM0sC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_steps = 3000\n",
        "batch_size = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nGz13sLTcGBp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "outputId": "ead110e3-298f-42a9-c1c1-55815f05e907"
      },
      "cell_type": "code",
      "source": [
        "!wget http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz /tmp/"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-05-09 14:02:13--  http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 170052171 (162M) [application/x-gzip]\n",
            "Saving to: ‘cifar-10-binary.tar.gz’\n",
            "\n",
            "cifar-10-binary.tar  94%[=================>  ] 153.33M  3.12MB/s    eta 3s     "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "cifar-10-binary.tar 100%[===================>] 162.17M  3.26MB/s    in 50s     \n",
            "\n",
            "2018-05-09 14:03:03 (3.27 MB/s) - ‘cifar-10-binary.tar.gz’ saved [170052171/170052171]\n",
            "\n",
            "/tmp/: Scheme missing.\n",
            "FINISHED --2018-05-09 14:03:03--\n",
            "Total wall clock time: 50s\n",
            "Downloaded: 1 files, 162M in 50s (3.27 MB/s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FZqOK9F5dj7L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!tar -zxf cifar-10-binary.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CoAn2nuid9Kn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_dir = 'cifar-10-batches-bin'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yNTwGPRXNCMO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def variable_with_weight_loss(shape, stddev, w1):\n",
        "  var = tf.Variable(tf.truncated_normal(shape,stddev=stddev))\n",
        "  if w1 is not None:\n",
        "    weight_loss = tf.multiply(tf.nn.l2_loss(var),w1,name='weight_loss')\n",
        "    tf.add_to_collection('losses',weight_loss)\n",
        "  return var"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GJylxpUy63b6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "45fb9e2e-9f07-4c9d-86ee-c7595ef220e0"
      },
      "cell_type": "code",
      "source": [
        "#使用cifar10类下载数据集，并解压、展开到其默认位置\n",
        "tf.app.flags.DEFINE_string('f', '', 'kernel') #解决错误：UnrecognizedFlagError: Unknown command line flag 'f'\n",
        "\n",
        "cifar10.maybe_download_and_extract()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">> Downloading cifar-10-binary.tar.gz 31.4%"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aR2FG6-n8cb5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 数据增强(Data Augmentation)\n",
        "数据增强操作包括随机的水平翻转、随机剪切一块24x24大小的图片(tf.random_crop)、设置随机的量度和对比度(tf.image.random_brightness、tf.image.random_contrast),\n",
        "\n",
        "以及对数据进行标准化tf.image.per_image_whitening(对数据减去均值，除以方差，保证数据0均值，方差为1)。通过这些操作，我们可以获得更多的样本(带噪声的)，\n",
        "\n",
        "原来的一张图片样本可以变为多张图片，相当于扩大样本量，对提高准确率非常有帮助。但是数据增强操作需要耗费大量的CPU时间。"
      ]
    },
    {
      "metadata": {
        "id": "rcUKOswo7P6g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c731f25b-7550-45e2-d5eb-e4acdb4f062e"
      },
      "cell_type": "code",
      "source": [
        "#使用distorted_inputs函数产生训练需要使用的数据，包括特征及其对应的label，这里返回的是已经封装好的tensor\n",
        "images_train,labels_train=cifar10_input.distorted_inputs(data_dir=data_dir, batch_size=batch_size)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yYlXgYrW7crC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#生成测试数据\n",
        "images_test, labels_test = cifar10_input.inputs(eval_data=True,data_dir=data_dir,batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TAgR9f_l93Id",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#输入数据的placeholder，包括特征和label\n",
        "image_holder = tf.placeholder(tf.float32, [batch_size,24,24,3])\n",
        "label_holder = tf.placeholder(tf.int32,[batch_size])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2LyrDUyf-lmD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "weight1 = variable_with_weight_loss(shape=[5,5,3,64],stddev=5e-2,w1=0.0)\n",
        "kernel1 = tf.nn.conv2d(image_holder,weight1,[1,1,1,1],padding='SAME')\n",
        "bias1 = tf.Variable(tf.constant(0.0, shape=[64]))\n",
        "conv1 = tf.nn.relu(tf.nn.bias_add(kernel1, bias1))\n",
        "pool1 = tf.nn.max_pool(conv1, ksize=[1,3,3,1], strides=[1,2,2,1],padding='SAME')\n",
        "norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.01/9.0,beta=0.75)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GZyldOm4B96J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#创建第二个卷积层\n",
        "weight2 = variable_with_weight_loss(shape=[5,5,64,64],stddev=5e-2,w1=0.0)\n",
        "kernel2 = tf.nn.conv2d(norm1, weight2,[1,1,1,1],padding='SAME')\n",
        "bias2 = tf.Variable(tf.constant(0.1, shape=[64]))\n",
        "conv2 = tf.nn.relu(tf.nn.bias_add(kernel2, bias2))\n",
        "norm2 = tf.nn.lrn(conv2,4,bias=1.0, alpha=0.001/9.0, beta=0.75)\n",
        "pool2 = tf.nn.max_pool(norm2, ksize=[1,3,3,1], strides=[1,2,2,1],padding='SAME')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z-ZKxouNC4hF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#全连接层，先把第二个卷积层的输出结果flatten\n",
        "reshape = tf.reshape(pool2, [batch_size,-1])\n",
        "dim = reshape.get_shape()[1].value\n",
        "weight3 = variable_with_weight_loss(shape=[dim, 384], stddev=0.04, w1=0.004)\n",
        "bias3 = tf.Variable(tf.constant(0.1, shape=[384]))\n",
        "local3 = tf.nn.relu(tf.matmul(reshape,weight3)+bias3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O-e5dpmbDg0h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#全连接层，隐藏节点下降一半\n",
        "weight4 = variable_with_weight_loss(shape=[384,192], stddev=0.04, w1=0.004)\n",
        "bias4 = tf.Variable(tf.constant(0.1, shape=[192]))\n",
        "local4 = tf.nn.relu(tf.matmul(local3, weight4)+bias4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W9QeHqOID5Jm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#最后一层\n",
        "weight5 = variable_with_weight_loss(shape=[192,10], stddev=1/192.0, w1=0.0)\n",
        "bias5 = tf.Variable(tf.constant(0.0, shape=[10]))\n",
        "logits = tf.add(tf.matmul(local4, weight5),bias5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GUDojsuREUVF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def loss(logits, labels):\n",
        "  labels = tf.cast(labels, tf.int64)\n",
        "  cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "      logits = logits, labels=labels, name='cross_entropy_per_example'\n",
        "  )\n",
        "  cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy')\n",
        "  tf.add_to_collection('losses', cross_entropy_mean)\n",
        "  \n",
        "  return tf.add_n(tf.get_collection('losses'), name='total_loss')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q1fgKou4E5zT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loss = loss(logits,label_holder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HBD85zmzFAeM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_op = tf.train.AdamOptimizer(1e-3).minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hrkSjRPmFHji",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "top_k_op = tf.nn.in_top_k(logits, label_holder, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UIgqg_OvFPOm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess = tf.InteractiveSession()\n",
        "tf.global_variables_initializer().run()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "boYuBPZ7FWzs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        },
        "outputId": "8c8ad7c1-3fc6-4171-d185-dab92074cb27"
      },
      "cell_type": "code",
      "source": [
        "tf.train.start_queue_runners()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<Thread(QueueRunnerThread-input_producer-input_producer/input_producer_EnqueueMany, started daemon 140544317970176)>,\n",
              " <Thread(QueueRunnerThread-shuffle_batch/random_shuffle_queue-shuffle_batch/random_shuffle_queue_enqueue, started daemon 140544309577472)>,\n",
              " <Thread(QueueRunnerThread-shuffle_batch/random_shuffle_queue-shuffle_batch/random_shuffle_queue_enqueue, started daemon 140544301184768)>,\n",
              " <Thread(QueueRunnerThread-shuffle_batch/random_shuffle_queue-shuffle_batch/random_shuffle_queue_enqueue, started daemon 140544292792064)>,\n",
              " <Thread(QueueRunnerThread-shuffle_batch/random_shuffle_queue-shuffle_batch/random_shuffle_queue_enqueue, started daemon 140544284399360)>,\n",
              " <Thread(QueueRunnerThread-shuffle_batch/random_shuffle_queue-shuffle_batch/random_shuffle_queue_enqueue, started daemon 140544276006656)>,\n",
              " <Thread(QueueRunnerThread-shuffle_batch/random_shuffle_queue-shuffle_batch/random_shuffle_queue_enqueue, started daemon 140544267613952)>,\n",
              " <Thread(QueueRunnerThread-shuffle_batch/random_shuffle_queue-shuffle_batch/random_shuffle_queue_enqueue, started daemon 140544259221248)>,\n",
              " <Thread(QueueRunnerThread-shuffle_batch/random_shuffle_queue-shuffle_batch/random_shuffle_queue_enqueue, started daemon 140544250828544)>,\n",
              " <Thread(QueueRunnerThread-shuffle_batch/random_shuffle_queue-shuffle_batch/random_shuffle_queue_enqueue, started daemon 140544242435840)>,\n",
              " <Thread(QueueRunnerThread-shuffle_batch/random_shuffle_queue-shuffle_batch/random_shuffle_queue_enqueue, started daemon 140544234043136)>,\n",
              " <Thread(QueueRunnerThread-shuffle_batch/random_shuffle_queue-shuffle_batch/random_shuffle_queue_enqueue, started daemon 140544225650432)>,\n",
              " <Thread(QueueRunnerThread-shuffle_batch/random_shuffle_queue-shuffle_batch/random_shuffle_queue_enqueue, started daemon 140544217257728)>,\n",
              " <Thread(QueueRunnerThread-shuffle_batch/random_shuffle_queue-shuffle_batch/random_shuffle_queue_enqueue, started daemon 140544208865024)>,\n",
              " <Thread(QueueRunnerThread-shuffle_batch/random_shuffle_queue-shuffle_batch/random_shuffle_queue_enqueue, started daemon 140544200472320)>,\n",
              " <Thread(QueueRunnerThread-shuffle_batch/random_shuffle_queue-shuffle_batch/random_shuffle_queue_enqueue, started daemon 140544183686912)>,\n",
              " <Thread(QueueRunnerThread-shuffle_batch/random_shuffle_queue-shuffle_batch/random_shuffle_queue_enqueue, started daemon 140544175294208)>,\n",
              " <Thread(QueueRunnerThread-input/input_producer-input/input_producer/input_producer_EnqueueMany, started daemon 140544166901504)>,\n",
              " <Thread(QueueRunnerThread-batch/fifo_queue-batch/fifo_queue_enqueue, started daemon 140544158508800)>,\n",
              " <Thread(QueueRunnerThread-batch/fifo_queue-batch/fifo_queue_enqueue, started daemon 140544150116096)>,\n",
              " <Thread(QueueRunnerThread-batch/fifo_queue-batch/fifo_queue_enqueue, started daemon 140544141723392)>,\n",
              " <Thread(QueueRunnerThread-batch/fifo_queue-batch/fifo_queue_enqueue, started daemon 140544133330688)>,\n",
              " <Thread(QueueRunnerThread-batch/fifo_queue-batch/fifo_queue_enqueue, started daemon 140544124937984)>,\n",
              " <Thread(QueueRunnerThread-batch/fifo_queue-batch/fifo_queue_enqueue, started daemon 140544108152576)>,\n",
              " <Thread(QueueRunnerThread-batch/fifo_queue-batch/fifo_queue_enqueue, started daemon 140544099759872)>,\n",
              " <Thread(QueueRunnerThread-batch/fifo_queue-batch/fifo_queue_enqueue, started daemon 140544091367168)>,\n",
              " <Thread(QueueRunnerThread-batch/fifo_queue-batch/fifo_queue_enqueue, started daemon 140544082974464)>,\n",
              " <Thread(QueueRunnerThread-batch/fifo_queue-batch/fifo_queue_enqueue, started daemon 140544074319616)>,\n",
              " <Thread(QueueRunnerThread-batch/fifo_queue-batch/fifo_queue_enqueue, started daemon 140544065926912)>,\n",
              " <Thread(QueueRunnerThread-batch/fifo_queue-batch/fifo_queue_enqueue, started daemon 140544057534208)>,\n",
              " <Thread(QueueRunnerThread-batch/fifo_queue-batch/fifo_queue_enqueue, started daemon 140544049141504)>,\n",
              " <Thread(QueueRunnerThread-batch/fifo_queue-batch/fifo_queue_enqueue, started daemon 140544040748800)>,\n",
              " <Thread(QueueRunnerThread-batch/fifo_queue-batch/fifo_queue_enqueue, started daemon 140544032356096)>,\n",
              " <Thread(QueueRunnerThread-batch/fifo_queue-batch/fifo_queue_enqueue, started daemon 140544023963392)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "1hAKvNUMFaJp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "39fc607d-6fd0-4ee3-ffec-5ea30f21babf"
      },
      "cell_type": "code",
      "source": [
        "for step in range(max_steps):\n",
        "  start_time = time.time()\n",
        "  image_batch, label_batch=sess.run([images_train,labels_train])\n",
        "  _, loss_value = sess.run([train_op, loss],\n",
        "                          feed_dict={image_holder:image_batch, label_holder:label_batch})\n",
        "  duration = time.time()-start_time\n",
        "  \n",
        "  if step % 10 ==0:\n",
        "    examples_per_sec = batch_size/duration\n",
        "    sec_per_batch=float(duration)\n",
        "    \n",
        "    format_str=('step %d, loss=%.2f(%.1f examples/sec; %.3f sec/batch)')\n",
        "    print(format_str % (step, loss_value, examples_per_sec, sec_per_batch))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step 0, loss=4.68(17.1 examples/sec; 7.500 sec/batch)\n",
            "step 10, loss=3.68(84.9 examples/sec; 1.508 sec/batch)\n",
            "step 20, loss=3.09(82.5 examples/sec; 1.552 sec/batch)\n",
            "step 30, loss=2.75(86.0 examples/sec; 1.488 sec/batch)\n",
            "step 40, loss=2.39(87.5 examples/sec; 1.463 sec/batch)\n",
            "step 50, loss=2.26(81.0 examples/sec; 1.580 sec/batch)\n",
            "step 60, loss=2.20(87.4 examples/sec; 1.465 sec/batch)\n",
            "step 70, loss=2.11(90.0 examples/sec; 1.422 sec/batch)\n",
            "step 80, loss=2.01(86.8 examples/sec; 1.474 sec/batch)\n",
            "step 90, loss=2.12(80.7 examples/sec; 1.586 sec/batch)\n",
            "step 100, loss=1.99(78.6 examples/sec; 1.629 sec/batch)\n",
            "step 110, loss=2.00(80.9 examples/sec; 1.582 sec/batch)\n",
            "step 120, loss=1.84(81.3 examples/sec; 1.574 sec/batch)\n",
            "step 130, loss=1.92(85.1 examples/sec; 1.505 sec/batch)\n",
            "step 140, loss=1.92(85.0 examples/sec; 1.506 sec/batch)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tr1ghM7xFypI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c0674bc0-258b-4084-c227-4562f3dda2c6"
      },
      "cell_type": "code",
      "source": [
        "num_examples = 10000\n",
        "import math\n",
        "num_iter = int(math.ceil(num_examples/batch_size))\n",
        "true_count = 0\n",
        "total_sample_count = num_iter*batch_size\n",
        "step = 0\n",
        "while step < num_iter:\n",
        "  image_batch, label_batch = sess.run([images_test,labels_test])\n",
        "  predictions = sess.run([top_k_op], feed_dict={image_holder:image_batch,label_holder:label_batch})\n",
        "  true_count += np.sum(predictions)\n",
        "  step+=1\n",
        "  \n",
        "  \n",
        "precision = true_count/total_sample_count\n",
        "print('precision @ 1 = %.3f' % precision)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "precision @ 1 = 0.712\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ifm6v1a1plUH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}