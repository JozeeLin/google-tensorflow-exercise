{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bidirectional LSTM Classifier.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/JozeeLin/google-tensorflow-exercise/blob/master/Bidirectional_LSTM_Classifier.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "0D6sSGYr8c8n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "双向循环神经网络(Bidirectional Recurrent Neural Networks,Bi-RNN)的主要目标是增加RNN可利用的信息。比如普通的MLP对数据长度等有限制，而RNN虽然可以处理不固定长度的时序数据，\n",
        "\n",
        "但是无法利用某个历史输入的未来信息。Bi-RNN则正好相反，它可以同时使用时序数据中某个输入的历史及未来数据。其实现原理很简单，将时序方向相反的两个循环神经网络连接到同一个输出，\n",
        "\n",
        "通过这种结构，输出层就可以同时获取历史和未来信息了。\n",
        "\n",
        "在需要上下文环境的情况中，Bi-RNN将会非常有用，比如在手写文字识别时，如果有当前要识别的单词的前面和后面一个单词的信息，那么将非常有利于识别。同样的，当我们在阅读文章时，\n",
        "\n",
        "有时也需要通过下文的语境来预测文中某句话的准确含义。**对语言模型这类问题，可能Bi-RNN并不合适，因为我们的目标就是通过前文预测下一个单词，这里不能讲下文信息传给模型**。\n",
        "\n",
        "对于很多分类问题，如手写文字识别、机器翻译、蛋白结构预测等，使用Bi-RNN将会大大提升模型效果。\n",
        "\n",
        "**百度在其语音识别中也是通过Bi-RNN综合考虑上下文语境，将其模型准确率大大提升**。\n",
        "\n",
        "Bi-RNN网络结构的核心是把一个普通的单向的RNN拆成两个方向，一个是随时序正向的，一个是逆着时序的反向的。这样当前时间节点的输出就可以同时利用正向、反向两个方向的信息，\n",
        "\n",
        "而不像普通RNN需要等到后面时间节点才可以获取未来信息。\n",
        "\n",
        "## 本节代码来自TensorFlow-Examples的开源实现"
      ]
    },
    {
      "metadata": {
        "id": "ggadkeBi8LIr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "outputId": "c037b8c8-2155-4b81-c6f3-d64440c7e4f1"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets('/tmp/data/', one_hot=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-1-e0c1a96c324a>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ssCNZd9wCfdY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01\n",
        "max_samples = 400000\n",
        "batch_size = 128\n",
        "display_step = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ih6o_KOwCz8v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_input = 28\n",
        "n_steps = 28\n",
        "n_hidden = 256\n",
        "n_classes = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OTU0nLtMC7en",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = tf.placeholder('float',[None, n_steps, n_input])\n",
        "y = tf.placeholder('float', [None, n_classes])\n",
        "\n",
        "weights = tf.Variable(tf.random_normal([2*n_hidden, n_classes]))\n",
        "biases = tf.Variable(tf.random_normal([n_classes]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7BMNWN_AD2sL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def BiRNN(x, weights, biases):\n",
        "  x = tf.transpose(x, [1,0,2])\n",
        "  x = tf.reshape(x, [-1, n_input])\n",
        "  x = tf.split(x, n_steps)\n",
        "  \n",
        "  lstm_fw_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, forget_bias=1.0)\n",
        "  lstm_bw_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, forget_bias=1.0)\n",
        "  \n",
        "  outputs, _, _ = tf.contrib.rnn.static_bidirectional_rnn(lstm_fw_cell, lstm_bw_cell, x, dtype=tf.float32)\n",
        "  \n",
        "  return tf.matmul(outputs[-1], weights)+biases"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Swi1JCvfEeMs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "52218397-e535-4a0e-c0cb-93bfca10af31"
      },
      "cell_type": "code",
      "source": [
        "pred = BiRNN(x, weights, biases)\n",
        "\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred,labels=y))\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "\n",
        "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-6-dbc493d3403a>:3: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x3-wJMUBFJJY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5726
        },
        "outputId": "0ea57f9e-c69b-4174-9185-97aec4fdbba0"
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  \n",
        "  step = 1\n",
        "  while step*batch_size < max_samples:\n",
        "    batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
        "    \n",
        "    batch_x = batch_x.reshape((batch_size, n_steps, n_input))\n",
        "    \n",
        "    sess.run(optimizer, feed_dict={x:batch_x,y:batch_y})\n",
        "    \n",
        "    if step%display_step == 0:\n",
        "      acc = sess.run(accuracy, feed_dict={x:batch_x, y:batch_y})\n",
        "      loss = sess.run(cost, feed_dict={x:batch_x, y:batch_y})\n",
        "      print('Iter '+str(step*batch_size)+\", Minibatch Loss= \"+ \\\n",
        "           \"{:.6}\".format(loss)+\", Training Accuracy= \"+\\\n",
        "           \"{:.5f}\".format(acc))\n",
        "      \n",
        "    step += 1\n",
        "  print('Optimization Finished!')\n",
        "  \n",
        "  #对mnist.test.images中全部的测试数据进行预测，并将准确率展示出来\n",
        "  test_len = 10000\n",
        "  test_data = mnist.test.images[:test_len].reshape((-1, n_steps, n_input))\n",
        "  test_label = mnist.test.labels[:test_len]\n",
        "  print('Testing Accuracy:', sess.run(accuracy, feed_dict={x:test_data, y:test_label}))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iter 1280, Minibatch Loss= 2.35805, Training Accuracy= 0.25000\n",
            "Iter 2560, Minibatch Loss= 1.42496, Training Accuracy= 0.52344\n",
            "Iter 3840, Minibatch Loss= 1.02555, Training Accuracy= 0.62500\n",
            "Iter 5120, Minibatch Loss= 1.08392, Training Accuracy= 0.64844\n",
            "Iter 6400, Minibatch Loss= 0.559484, Training Accuracy= 0.82031\n",
            "Iter 7680, Minibatch Loss= 0.545343, Training Accuracy= 0.78125\n",
            "Iter 8960, Minibatch Loss= 0.369744, Training Accuracy= 0.86719\n",
            "Iter 10240, Minibatch Loss= 0.210627, Training Accuracy= 0.93750\n",
            "Iter 11520, Minibatch Loss= 0.117498, Training Accuracy= 0.97656\n",
            "Iter 12800, Minibatch Loss= 0.25528, Training Accuracy= 0.92188\n",
            "Iter 14080, Minibatch Loss= 0.391438, Training Accuracy= 0.85938\n",
            "Iter 15360, Minibatch Loss= 0.239144, Training Accuracy= 0.92969\n",
            "Iter 16640, Minibatch Loss= 0.408407, Training Accuracy= 0.91406\n",
            "Iter 17920, Minibatch Loss= 0.288785, Training Accuracy= 0.92969\n",
            "Iter 19200, Minibatch Loss= 0.33451, Training Accuracy= 0.88281\n",
            "Iter 20480, Minibatch Loss= 0.141443, Training Accuracy= 0.95312\n",
            "Iter 21760, Minibatch Loss= 0.15745, Training Accuracy= 0.93750\n",
            "Iter 23040, Minibatch Loss= 0.177451, Training Accuracy= 0.96094\n",
            "Iter 24320, Minibatch Loss= 0.18699, Training Accuracy= 0.96094\n",
            "Iter 25600, Minibatch Loss= 0.231225, Training Accuracy= 0.94531\n",
            "Iter 26880, Minibatch Loss= 0.0387208, Training Accuracy= 1.00000\n",
            "Iter 28160, Minibatch Loss= 0.0601141, Training Accuracy= 0.99219\n",
            "Iter 29440, Minibatch Loss= 0.0591694, Training Accuracy= 0.96875\n",
            "Iter 30720, Minibatch Loss= 0.0890655, Training Accuracy= 0.96094\n",
            "Iter 32000, Minibatch Loss= 0.189616, Training Accuracy= 0.94531\n",
            "Iter 33280, Minibatch Loss= 0.0371828, Training Accuracy= 0.99219\n",
            "Iter 34560, Minibatch Loss= 0.111378, Training Accuracy= 0.97656\n",
            "Iter 35840, Minibatch Loss= 0.0925811, Training Accuracy= 0.98438\n",
            "Iter 37120, Minibatch Loss= 0.0676083, Training Accuracy= 0.97656\n",
            "Iter 38400, Minibatch Loss= 0.115404, Training Accuracy= 0.96094\n",
            "Iter 39680, Minibatch Loss= 0.0455389, Training Accuracy= 0.99219\n",
            "Iter 40960, Minibatch Loss= 0.161343, Training Accuracy= 0.94531\n",
            "Iter 42240, Minibatch Loss= 0.111668, Training Accuracy= 0.96094\n",
            "Iter 43520, Minibatch Loss= 0.119563, Training Accuracy= 0.97656\n",
            "Iter 44800, Minibatch Loss= 0.102419, Training Accuracy= 0.96875\n",
            "Iter 46080, Minibatch Loss= 0.0805602, Training Accuracy= 0.97656\n",
            "Iter 47360, Minibatch Loss= 0.0889969, Training Accuracy= 0.96875\n",
            "Iter 48640, Minibatch Loss= 0.052994, Training Accuracy= 0.98438\n",
            "Iter 49920, Minibatch Loss= 0.0912927, Training Accuracy= 0.96094\n",
            "Iter 51200, Minibatch Loss= 0.0814201, Training Accuracy= 0.98438\n",
            "Iter 52480, Minibatch Loss= 0.112699, Training Accuracy= 0.96094\n",
            "Iter 53760, Minibatch Loss= 0.104895, Training Accuracy= 0.96875\n",
            "Iter 55040, Minibatch Loss= 0.0603785, Training Accuracy= 0.98438\n",
            "Iter 56320, Minibatch Loss= 0.0296109, Training Accuracy= 0.99219\n",
            "Iter 57600, Minibatch Loss= 0.048875, Training Accuracy= 0.99219\n",
            "Iter 58880, Minibatch Loss= 0.176332, Training Accuracy= 0.93750\n",
            "Iter 60160, Minibatch Loss= 0.0289828, Training Accuracy= 0.99219\n",
            "Iter 61440, Minibatch Loss= 0.11846, Training Accuracy= 0.97656\n",
            "Iter 62720, Minibatch Loss= 0.0594014, Training Accuracy= 0.98438\n",
            "Iter 64000, Minibatch Loss= 0.0220837, Training Accuracy= 1.00000\n",
            "Iter 65280, Minibatch Loss= 0.0295992, Training Accuracy= 0.99219\n",
            "Iter 66560, Minibatch Loss= 0.0893024, Training Accuracy= 0.96094\n",
            "Iter 67840, Minibatch Loss= 0.0887786, Training Accuracy= 0.97656\n",
            "Iter 69120, Minibatch Loss= 0.0729792, Training Accuracy= 0.98438\n",
            "Iter 70400, Minibatch Loss= 0.0376596, Training Accuracy= 0.98438\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 71680, Minibatch Loss= 0.0882015, Training Accuracy= 0.96875\n",
            "Iter 72960, Minibatch Loss= 0.0570838, Training Accuracy= 0.98438\n",
            "Iter 74240, Minibatch Loss= 0.0510431, Training Accuracy= 0.98438\n",
            "Iter 75520, Minibatch Loss= 0.070563, Training Accuracy= 0.98438\n",
            "Iter 76800, Minibatch Loss= 0.0549392, Training Accuracy= 0.98438\n",
            "Iter 78080, Minibatch Loss= 0.0593532, Training Accuracy= 0.97656\n",
            "Iter 79360, Minibatch Loss= 0.0308864, Training Accuracy= 0.99219\n",
            "Iter 80640, Minibatch Loss= 0.0529998, Training Accuracy= 0.98438\n",
            "Iter 81920, Minibatch Loss= 0.0374699, Training Accuracy= 0.98438\n",
            "Iter 83200, Minibatch Loss= 0.0418591, Training Accuracy= 0.98438\n",
            "Iter 84480, Minibatch Loss= 0.0196275, Training Accuracy= 0.99219\n",
            "Iter 85760, Minibatch Loss= 0.0818101, Training Accuracy= 0.97656\n",
            "Iter 87040, Minibatch Loss= 0.0266132, Training Accuracy= 1.00000\n",
            "Iter 88320, Minibatch Loss= 0.0238477, Training Accuracy= 0.99219\n",
            "Iter 89600, Minibatch Loss= 0.122139, Training Accuracy= 0.98438\n",
            "Iter 90880, Minibatch Loss= 0.0631226, Training Accuracy= 0.98438\n",
            "Iter 92160, Minibatch Loss= 0.0200706, Training Accuracy= 0.99219\n",
            "Iter 93440, Minibatch Loss= 0.0640226, Training Accuracy= 0.97656\n",
            "Iter 94720, Minibatch Loss= 0.0251473, Training Accuracy= 1.00000\n",
            "Iter 96000, Minibatch Loss= 0.104417, Training Accuracy= 0.96094\n",
            "Iter 97280, Minibatch Loss= 0.0264229, Training Accuracy= 1.00000\n",
            "Iter 98560, Minibatch Loss= 0.135001, Training Accuracy= 0.96094\n",
            "Iter 99840, Minibatch Loss= 0.0552071, Training Accuracy= 0.99219\n",
            "Iter 101120, Minibatch Loss= 0.0799614, Training Accuracy= 0.98438\n",
            "Iter 102400, Minibatch Loss= 0.0280092, Training Accuracy= 0.99219\n",
            "Iter 103680, Minibatch Loss= 0.0654913, Training Accuracy= 0.98438\n",
            "Iter 104960, Minibatch Loss= 0.0969337, Training Accuracy= 0.96875\n",
            "Iter 106240, Minibatch Loss= 0.0680507, Training Accuracy= 0.96094\n",
            "Iter 107520, Minibatch Loss= 0.115814, Training Accuracy= 0.98438\n",
            "Iter 108800, Minibatch Loss= 0.0720964, Training Accuracy= 0.97656\n",
            "Iter 110080, Minibatch Loss= 0.0511621, Training Accuracy= 0.98438\n",
            "Iter 111360, Minibatch Loss= 0.0291031, Training Accuracy= 0.99219\n",
            "Iter 112640, Minibatch Loss= 0.0903829, Training Accuracy= 0.97656\n",
            "Iter 113920, Minibatch Loss= 0.0405926, Training Accuracy= 0.98438\n",
            "Iter 115200, Minibatch Loss= 0.0211245, Training Accuracy= 1.00000\n",
            "Iter 116480, Minibatch Loss= 0.00770178, Training Accuracy= 1.00000\n",
            "Iter 117760, Minibatch Loss= 0.0141932, Training Accuracy= 1.00000\n",
            "Iter 119040, Minibatch Loss= 0.0937186, Training Accuracy= 0.97656\n",
            "Iter 120320, Minibatch Loss= 0.024199, Training Accuracy= 0.99219\n",
            "Iter 121600, Minibatch Loss= 0.0256953, Training Accuracy= 1.00000\n",
            "Iter 122880, Minibatch Loss= 0.010456, Training Accuracy= 1.00000\n",
            "Iter 124160, Minibatch Loss= 0.0423797, Training Accuracy= 0.98438\n",
            "Iter 125440, Minibatch Loss= 0.0166293, Training Accuracy= 0.99219\n",
            "Iter 126720, Minibatch Loss= 0.084379, Training Accuracy= 0.98438\n",
            "Iter 128000, Minibatch Loss= 0.0495929, Training Accuracy= 0.99219\n",
            "Iter 129280, Minibatch Loss= 0.0168072, Training Accuracy= 1.00000\n",
            "Iter 130560, Minibatch Loss= 0.00947701, Training Accuracy= 1.00000\n",
            "Iter 131840, Minibatch Loss= 0.0175893, Training Accuracy= 0.99219\n",
            "Iter 133120, Minibatch Loss= 0.0672308, Training Accuracy= 0.98438\n",
            "Iter 134400, Minibatch Loss= 0.0531214, Training Accuracy= 0.99219\n",
            "Iter 135680, Minibatch Loss= 0.0339632, Training Accuracy= 0.99219\n",
            "Iter 136960, Minibatch Loss= 0.0164079, Training Accuracy= 1.00000\n",
            "Iter 138240, Minibatch Loss= 0.01676, Training Accuracy= 1.00000\n",
            "Iter 139520, Minibatch Loss= 0.113204, Training Accuracy= 0.97656\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 140800, Minibatch Loss= 0.0906404, Training Accuracy= 0.97656\n",
            "Iter 142080, Minibatch Loss= 0.0152759, Training Accuracy= 1.00000\n",
            "Iter 143360, Minibatch Loss= 0.0147332, Training Accuracy= 1.00000\n",
            "Iter 144640, Minibatch Loss= 0.0120303, Training Accuracy= 1.00000\n",
            "Iter 145920, Minibatch Loss= 0.0508728, Training Accuracy= 0.98438\n",
            "Iter 147200, Minibatch Loss= 0.0271843, Training Accuracy= 0.99219\n",
            "Iter 148480, Minibatch Loss= 0.0478371, Training Accuracy= 0.97656\n",
            "Iter 149760, Minibatch Loss= 0.0282381, Training Accuracy= 0.99219\n",
            "Iter 151040, Minibatch Loss= 0.0684309, Training Accuracy= 0.98438\n",
            "Iter 152320, Minibatch Loss= 0.0509333, Training Accuracy= 0.97656\n",
            "Iter 153600, Minibatch Loss= 0.0499943, Training Accuracy= 0.99219\n",
            "Iter 154880, Minibatch Loss= 0.0148821, Training Accuracy= 1.00000\n",
            "Iter 156160, Minibatch Loss= 0.0341163, Training Accuracy= 0.98438\n",
            "Iter 157440, Minibatch Loss= 0.0124518, Training Accuracy= 1.00000\n",
            "Iter 158720, Minibatch Loss= 0.0400689, Training Accuracy= 0.98438\n",
            "Iter 160000, Minibatch Loss= 0.0127539, Training Accuracy= 1.00000\n",
            "Iter 161280, Minibatch Loss= 0.0157038, Training Accuracy= 1.00000\n",
            "Iter 162560, Minibatch Loss= 0.0742778, Training Accuracy= 0.98438\n",
            "Iter 163840, Minibatch Loss= 0.0112064, Training Accuracy= 1.00000\n",
            "Iter 165120, Minibatch Loss= 0.0375691, Training Accuracy= 0.97656\n",
            "Iter 166400, Minibatch Loss= 0.0343279, Training Accuracy= 0.99219\n",
            "Iter 167680, Minibatch Loss= 0.0619161, Training Accuracy= 0.99219\n",
            "Iter 168960, Minibatch Loss= 0.0197825, Training Accuracy= 0.99219\n",
            "Iter 170240, Minibatch Loss= 0.00730918, Training Accuracy= 1.00000\n",
            "Iter 171520, Minibatch Loss= 0.0161591, Training Accuracy= 1.00000\n",
            "Iter 172800, Minibatch Loss= 0.00901769, Training Accuracy= 1.00000\n",
            "Iter 174080, Minibatch Loss= 0.0170005, Training Accuracy= 1.00000\n",
            "Iter 175360, Minibatch Loss= 0.0825449, Training Accuracy= 0.97656\n",
            "Iter 176640, Minibatch Loss= 0.0189789, Training Accuracy= 1.00000\n",
            "Iter 177920, Minibatch Loss= 0.0176705, Training Accuracy= 0.99219\n",
            "Iter 179200, Minibatch Loss= 0.0168565, Training Accuracy= 1.00000\n",
            "Iter 180480, Minibatch Loss= 0.0665751, Training Accuracy= 0.98438\n",
            "Iter 181760, Minibatch Loss= 0.0251729, Training Accuracy= 0.99219\n",
            "Iter 183040, Minibatch Loss= 0.0568473, Training Accuracy= 0.97656\n",
            "Iter 184320, Minibatch Loss= 0.0754175, Training Accuracy= 0.96875\n",
            "Iter 185600, Minibatch Loss= 0.0203557, Training Accuracy= 1.00000\n",
            "Iter 186880, Minibatch Loss= 0.00868117, Training Accuracy= 1.00000\n",
            "Iter 188160, Minibatch Loss= 0.0733338, Training Accuracy= 0.99219\n",
            "Iter 189440, Minibatch Loss= 0.107149, Training Accuracy= 0.97656\n",
            "Iter 190720, Minibatch Loss= 0.0337912, Training Accuracy= 0.99219\n",
            "Iter 192000, Minibatch Loss= 0.0391215, Training Accuracy= 0.98438\n",
            "Iter 193280, Minibatch Loss= 0.0598148, Training Accuracy= 0.96875\n",
            "Iter 194560, Minibatch Loss= 0.0127988, Training Accuracy= 1.00000\n",
            "Iter 195840, Minibatch Loss= 0.0227273, Training Accuracy= 0.99219\n",
            "Iter 197120, Minibatch Loss= 0.0366654, Training Accuracy= 0.98438\n",
            "Iter 198400, Minibatch Loss= 0.0793467, Training Accuracy= 0.96875\n",
            "Iter 199680, Minibatch Loss= 0.0485985, Training Accuracy= 0.98438\n",
            "Iter 200960, Minibatch Loss= 0.0504338, Training Accuracy= 0.99219\n",
            "Iter 202240, Minibatch Loss= 0.0418743, Training Accuracy= 0.98438\n",
            "Iter 203520, Minibatch Loss= 0.0205874, Training Accuracy= 0.99219\n",
            "Iter 204800, Minibatch Loss= 0.0172095, Training Accuracy= 0.99219\n",
            "Iter 206080, Minibatch Loss= 0.0601991, Training Accuracy= 0.97656\n",
            "Iter 207360, Minibatch Loss= 0.0192094, Training Accuracy= 1.00000\n",
            "Iter 208640, Minibatch Loss= 0.108828, Training Accuracy= 0.96875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 209920, Minibatch Loss= 0.065367, Training Accuracy= 0.97656\n",
            "Iter 211200, Minibatch Loss= 0.0199244, Training Accuracy= 0.98438\n",
            "Iter 212480, Minibatch Loss= 0.0925493, Training Accuracy= 0.98438\n",
            "Iter 213760, Minibatch Loss= 0.0178739, Training Accuracy= 0.99219\n",
            "Iter 215040, Minibatch Loss= 0.031884, Training Accuracy= 0.99219\n",
            "Iter 216320, Minibatch Loss= 0.082046, Training Accuracy= 0.97656\n",
            "Iter 217600, Minibatch Loss= 0.0370816, Training Accuracy= 0.98438\n",
            "Iter 218880, Minibatch Loss= 0.0438505, Training Accuracy= 0.99219\n",
            "Iter 220160, Minibatch Loss= 0.0814698, Training Accuracy= 0.98438\n",
            "Iter 221440, Minibatch Loss= 0.0224496, Training Accuracy= 0.99219\n",
            "Iter 222720, Minibatch Loss= 0.0621614, Training Accuracy= 0.98438\n",
            "Iter 224000, Minibatch Loss= 0.0166266, Training Accuracy= 1.00000\n",
            "Iter 225280, Minibatch Loss= 0.0276492, Training Accuracy= 0.98438\n",
            "Iter 226560, Minibatch Loss= 0.029827, Training Accuracy= 0.98438\n",
            "Iter 227840, Minibatch Loss= 0.0630167, Training Accuracy= 0.98438\n",
            "Iter 229120, Minibatch Loss= 0.0140164, Training Accuracy= 1.00000\n",
            "Iter 230400, Minibatch Loss= 0.0365685, Training Accuracy= 0.99219\n",
            "Iter 231680, Minibatch Loss= 0.00472858, Training Accuracy= 1.00000\n",
            "Iter 232960, Minibatch Loss= 0.0162219, Training Accuracy= 1.00000\n",
            "Iter 234240, Minibatch Loss= 0.0155525, Training Accuracy= 1.00000\n",
            "Iter 235520, Minibatch Loss= 0.017623, Training Accuracy= 1.00000\n",
            "Iter 236800, Minibatch Loss= 0.0304082, Training Accuracy= 0.99219\n",
            "Iter 238080, Minibatch Loss= 0.0368393, Training Accuracy= 0.99219\n",
            "Iter 239360, Minibatch Loss= 0.0113253, Training Accuracy= 0.99219\n",
            "Iter 240640, Minibatch Loss= 0.0110007, Training Accuracy= 0.99219\n",
            "Iter 241920, Minibatch Loss= 0.0399804, Training Accuracy= 0.99219\n",
            "Iter 243200, Minibatch Loss= 0.013735, Training Accuracy= 0.99219\n",
            "Iter 244480, Minibatch Loss= 0.0278017, Training Accuracy= 0.99219\n",
            "Iter 245760, Minibatch Loss= 0.040159, Training Accuracy= 0.99219\n",
            "Iter 247040, Minibatch Loss= 0.00854238, Training Accuracy= 1.00000\n",
            "Iter 248320, Minibatch Loss= 0.0171848, Training Accuracy= 0.99219\n",
            "Iter 249600, Minibatch Loss= 0.0894628, Training Accuracy= 0.97656\n",
            "Iter 250880, Minibatch Loss= 0.0179884, Training Accuracy= 0.99219\n",
            "Iter 252160, Minibatch Loss= 0.0549548, Training Accuracy= 0.98438\n",
            "Iter 253440, Minibatch Loss= 0.00932477, Training Accuracy= 1.00000\n",
            "Iter 254720, Minibatch Loss= 0.0834454, Training Accuracy= 0.98438\n",
            "Iter 256000, Minibatch Loss= 0.0340938, Training Accuracy= 0.99219\n",
            "Iter 257280, Minibatch Loss= 0.0228624, Training Accuracy= 0.99219\n",
            "Iter 258560, Minibatch Loss= 0.0180189, Training Accuracy= 1.00000\n",
            "Iter 259840, Minibatch Loss= 0.0618227, Training Accuracy= 0.99219\n",
            "Iter 261120, Minibatch Loss= 0.00828089, Training Accuracy= 1.00000\n",
            "Iter 262400, Minibatch Loss= 0.0267269, Training Accuracy= 0.99219\n",
            "Iter 263680, Minibatch Loss= 0.0154771, Training Accuracy= 1.00000\n",
            "Iter 264960, Minibatch Loss= 0.0330325, Training Accuracy= 0.98438\n",
            "Iter 266240, Minibatch Loss= 0.0412806, Training Accuracy= 0.99219\n",
            "Iter 267520, Minibatch Loss= 0.0766175, Training Accuracy= 0.97656\n",
            "Iter 268800, Minibatch Loss= 0.0741851, Training Accuracy= 0.98438\n",
            "Iter 270080, Minibatch Loss= 0.00575084, Training Accuracy= 1.00000\n",
            "Iter 271360, Minibatch Loss= 0.0313453, Training Accuracy= 0.99219\n",
            "Iter 272640, Minibatch Loss= 0.00901097, Training Accuracy= 1.00000\n",
            "Iter 273920, Minibatch Loss= 0.00921296, Training Accuracy= 1.00000\n",
            "Iter 275200, Minibatch Loss= 0.00591701, Training Accuracy= 1.00000\n",
            "Iter 276480, Minibatch Loss= 0.00750194, Training Accuracy= 1.00000\n",
            "Iter 277760, Minibatch Loss= 0.00204708, Training Accuracy= 1.00000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 279040, Minibatch Loss= 0.028718, Training Accuracy= 0.99219\n",
            "Iter 280320, Minibatch Loss= 0.00773497, Training Accuracy= 1.00000\n",
            "Iter 281600, Minibatch Loss= 0.00762161, Training Accuracy= 1.00000\n",
            "Iter 282880, Minibatch Loss= 0.0124966, Training Accuracy= 1.00000\n",
            "Iter 284160, Minibatch Loss= 0.053494, Training Accuracy= 0.98438\n",
            "Iter 285440, Minibatch Loss= 0.021671, Training Accuracy= 0.99219\n",
            "Iter 286720, Minibatch Loss= 0.0218721, Training Accuracy= 0.99219\n",
            "Iter 288000, Minibatch Loss= 0.00344791, Training Accuracy= 1.00000\n",
            "Iter 289280, Minibatch Loss= 0.0242906, Training Accuracy= 1.00000\n",
            "Iter 290560, Minibatch Loss= 0.00761749, Training Accuracy= 1.00000\n",
            "Iter 291840, Minibatch Loss= 0.00223829, Training Accuracy= 1.00000\n",
            "Iter 293120, Minibatch Loss= 0.03785, Training Accuracy= 0.98438\n",
            "Iter 294400, Minibatch Loss= 0.0755082, Training Accuracy= 0.97656\n",
            "Iter 295680, Minibatch Loss= 0.0110098, Training Accuracy= 1.00000\n",
            "Iter 296960, Minibatch Loss= 0.013355, Training Accuracy= 1.00000\n",
            "Iter 298240, Minibatch Loss= 0.0113273, Training Accuracy= 1.00000\n",
            "Iter 299520, Minibatch Loss= 0.0219172, Training Accuracy= 0.99219\n",
            "Iter 300800, Minibatch Loss= 0.0101699, Training Accuracy= 1.00000\n",
            "Iter 302080, Minibatch Loss= 0.0609043, Training Accuracy= 0.99219\n",
            "Iter 303360, Minibatch Loss= 0.000471669, Training Accuracy= 1.00000\n",
            "Iter 304640, Minibatch Loss= 0.0110006, Training Accuracy= 1.00000\n",
            "Iter 305920, Minibatch Loss= 0.0102592, Training Accuracy= 1.00000\n",
            "Iter 307200, Minibatch Loss= 0.0203741, Training Accuracy= 0.99219\n",
            "Iter 308480, Minibatch Loss= 0.0190152, Training Accuracy= 0.98438\n",
            "Iter 309760, Minibatch Loss= 0.0310445, Training Accuracy= 0.99219\n",
            "Iter 311040, Minibatch Loss= 0.0413427, Training Accuracy= 0.97656\n",
            "Iter 312320, Minibatch Loss= 0.00359118, Training Accuracy= 1.00000\n",
            "Iter 313600, Minibatch Loss= 0.00682996, Training Accuracy= 1.00000\n",
            "Iter 314880, Minibatch Loss= 0.0414688, Training Accuracy= 0.99219\n",
            "Iter 316160, Minibatch Loss= 0.0342116, Training Accuracy= 0.99219\n",
            "Iter 317440, Minibatch Loss= 0.0243755, Training Accuracy= 0.99219\n",
            "Iter 318720, Minibatch Loss= 0.0499677, Training Accuracy= 0.98438\n",
            "Iter 320000, Minibatch Loss= 0.103368, Training Accuracy= 0.97656\n",
            "Iter 321280, Minibatch Loss= 0.0091457, Training Accuracy= 1.00000\n",
            "Iter 322560, Minibatch Loss= 0.00230729, Training Accuracy= 1.00000\n",
            "Iter 323840, Minibatch Loss= 0.00427892, Training Accuracy= 1.00000\n",
            "Iter 325120, Minibatch Loss= 0.0194433, Training Accuracy= 0.99219\n",
            "Iter 326400, Minibatch Loss= 0.0285174, Training Accuracy= 0.98438\n",
            "Iter 327680, Minibatch Loss= 0.014833, Training Accuracy= 0.99219\n",
            "Iter 328960, Minibatch Loss= 0.0336163, Training Accuracy= 0.99219\n",
            "Iter 330240, Minibatch Loss= 0.0123769, Training Accuracy= 1.00000\n",
            "Iter 331520, Minibatch Loss= 0.0314842, Training Accuracy= 0.99219\n",
            "Iter 332800, Minibatch Loss= 0.0183465, Training Accuracy= 0.99219\n",
            "Iter 334080, Minibatch Loss= 0.00565458, Training Accuracy= 1.00000\n",
            "Iter 335360, Minibatch Loss= 0.015152, Training Accuracy= 1.00000\n",
            "Iter 336640, Minibatch Loss= 0.010514, Training Accuracy= 1.00000\n",
            "Iter 337920, Minibatch Loss= 0.00134006, Training Accuracy= 1.00000\n",
            "Iter 339200, Minibatch Loss= 0.0978861, Training Accuracy= 0.98438\n",
            "Iter 340480, Minibatch Loss= 0.0460831, Training Accuracy= 0.99219\n",
            "Iter 341760, Minibatch Loss= 0.0046722, Training Accuracy= 1.00000\n",
            "Iter 343040, Minibatch Loss= 0.0262051, Training Accuracy= 0.99219\n",
            "Iter 344320, Minibatch Loss= 0.0234539, Training Accuracy= 0.99219\n",
            "Iter 345600, Minibatch Loss= 0.0128693, Training Accuracy= 0.99219\n",
            "Iter 346880, Minibatch Loss= 0.00425059, Training Accuracy= 1.00000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 348160, Minibatch Loss= 0.00358348, Training Accuracy= 1.00000\n",
            "Iter 349440, Minibatch Loss= 0.0240266, Training Accuracy= 0.99219\n",
            "Iter 350720, Minibatch Loss= 0.00203763, Training Accuracy= 1.00000\n",
            "Iter 352000, Minibatch Loss= 0.0100538, Training Accuracy= 1.00000\n",
            "Iter 353280, Minibatch Loss= 0.00763917, Training Accuracy= 1.00000\n",
            "Iter 354560, Minibatch Loss= 0.00892685, Training Accuracy= 1.00000\n",
            "Iter 355840, Minibatch Loss= 0.00209191, Training Accuracy= 1.00000\n",
            "Iter 357120, Minibatch Loss= 0.0255446, Training Accuracy= 0.99219\n",
            "Iter 358400, Minibatch Loss= 0.0222952, Training Accuracy= 0.98438\n",
            "Iter 359680, Minibatch Loss= 0.0182557, Training Accuracy= 0.99219\n",
            "Iter 360960, Minibatch Loss= 0.0224101, Training Accuracy= 0.99219\n",
            "Iter 362240, Minibatch Loss= 0.0176188, Training Accuracy= 1.00000\n",
            "Iter 363520, Minibatch Loss= 0.0240097, Training Accuracy= 1.00000\n",
            "Iter 364800, Minibatch Loss= 0.0422063, Training Accuracy= 0.99219\n",
            "Iter 366080, Minibatch Loss= 0.0250617, Training Accuracy= 0.99219\n",
            "Iter 367360, Minibatch Loss= 0.0100231, Training Accuracy= 0.99219\n",
            "Iter 368640, Minibatch Loss= 0.00876208, Training Accuracy= 1.00000\n",
            "Iter 369920, Minibatch Loss= 0.00828614, Training Accuracy= 1.00000\n",
            "Iter 371200, Minibatch Loss= 0.00454627, Training Accuracy= 1.00000\n",
            "Iter 372480, Minibatch Loss= 0.0195673, Training Accuracy= 0.99219\n",
            "Iter 373760, Minibatch Loss= 0.0249292, Training Accuracy= 1.00000\n",
            "Iter 375040, Minibatch Loss= 0.00946708, Training Accuracy= 1.00000\n",
            "Iter 376320, Minibatch Loss= 0.0104131, Training Accuracy= 1.00000\n",
            "Iter 377600, Minibatch Loss= 0.00621039, Training Accuracy= 1.00000\n",
            "Iter 378880, Minibatch Loss= 0.0241957, Training Accuracy= 0.98438\n",
            "Iter 380160, Minibatch Loss= 0.0153271, Training Accuracy= 1.00000\n",
            "Iter 381440, Minibatch Loss= 0.0111706, Training Accuracy= 1.00000\n",
            "Iter 382720, Minibatch Loss= 0.0076702, Training Accuracy= 1.00000\n",
            "Iter 384000, Minibatch Loss= 0.0355089, Training Accuracy= 0.98438\n",
            "Iter 385280, Minibatch Loss= 0.00825097, Training Accuracy= 1.00000\n",
            "Iter 386560, Minibatch Loss= 0.00732491, Training Accuracy= 1.00000\n",
            "Iter 387840, Minibatch Loss= 0.00662777, Training Accuracy= 1.00000\n",
            "Iter 389120, Minibatch Loss= 0.0107886, Training Accuracy= 1.00000\n",
            "Iter 390400, Minibatch Loss= 0.00702783, Training Accuracy= 1.00000\n",
            "Iter 391680, Minibatch Loss= 0.0183734, Training Accuracy= 0.99219\n",
            "Iter 392960, Minibatch Loss= 0.0204011, Training Accuracy= 0.99219\n",
            "Iter 394240, Minibatch Loss= 0.00589679, Training Accuracy= 1.00000\n",
            "Iter 395520, Minibatch Loss= 0.00605301, Training Accuracy= 1.00000\n",
            "Iter 396800, Minibatch Loss= 0.0101715, Training Accuracy= 1.00000\n",
            "Iter 398080, Minibatch Loss= 0.0153309, Training Accuracy= 0.99219\n",
            "Iter 399360, Minibatch Loss= 0.0276312, Training Accuracy= 0.99219\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.9852\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "l2IyzD-SGgnN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}